# -*- coding: utf-8 -*-
"""ApexSentiment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u8aBzqukm59Ffv_m4veECP3EnIb09T9i

# **Data Cleaning**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import nltk

df = pd.read_csv("/content/drive/MyDrive/Apex_Legends_Steam_Reviews.csv")
df.tail()

#remove special characters from reviews
df["review"] = df["review"].str.replace(r'[^a-zA-Z0-9\s]', '', regex=True)

# Fill NaN values with empty strings before applying sentiment analysis
if df["review"].isnull().any():
    df.fillna({"review":""}, inplace=True)

from datetime import datetime

df["created"] = pd.to_datetime(df["created"]).dt.normalize()
df.tail()

#Split Data Into Seasons
seasons = {
    "Preseason": (datetime(2019, 2, 4),   datetime(2019, 3, 19)),
    "Season 1": (datetime(2019, 3, 19), datetime(2019, 6, 18)),
    "Season 2": (datetime(2019, 7, 2), datetime(2019, 10, 1)),
    "Season 3": (datetime(2019, 10, 1), datetime(2020, 2, 4)),
    "Season 4": (datetime(2020, 2, 4), datetime(2020, 5, 12)),
    "Season 5": (datetime(2020, 5, 12), datetime(2020, 8, 18)),
    "Season 6": (datetime(2020, 8, 18), datetime(2020, 11, 4)),
    "Season 7": (datetime(2020, 11, 4), datetime(2021, 2, 2)),
    "Season 8": (datetime(2021, 2, 2), datetime(2021, 5, 4)),
    "Season 9": (datetime(2021, 5, 4), datetime(2021, 8, 3)),
    "Season 10": (datetime(2021, 8, 3), datetime(2021, 11, 2)),
    "Season 11": (datetime(2021, 11, 2), datetime(2022, 2, 8)),
    "Season 12": (datetime(2022, 2, 8), datetime(2022, 5, 10)),
    "Season 13": (datetime(2022, 5, 10), datetime(2022, 8, 9)),
    "Season 14": (datetime(2022, 8, 9), datetime(2022, 11, 1)),
    "Season 15": (datetime(2022, 11, 1), datetime(2023, 2, 14)),
    "Season 16": (datetime(2023, 2, 14), datetime(2023, 5, 9)),
    "Season 17": (datetime(2023, 5, 9), datetime(2023, 8, 8)),
    "Season 18": (datetime(2023, 8, 8), datetime(2023, 10, 31)),
    "Season 19": (datetime(2023, 10, 31), datetime(2024, 2, 13)),
    "Season 20": (datetime(2024, 2, 13), datetime(2024, 5, 6)),
    "Season 21": (datetime(2024, 5, 7), datetime(2024, 8, 6)),
    "Season 22": (datetime(2024, 8, 6), datetime(2024, 11, 5)),
    "Season 23": (datetime(2024, 11, 5), datetime(2025, 2, 11)),
    "Season 24": (datetime(2025, 2, 11), datetime(2025, 5, 6)),
    "Season 25": (datetime(2025, 5, 6), datetime(2025, 7, 5)),  # approximate end date :contentReference[oaicite:1]{index=1}
}

#Data Starts at Season 15
start, end = seasons["Season 15"]
s15_mask = (df['created'] >= start) & (df['created'] <= end)
df_s15 = df.loc[s15_mask]
df_s15["voted_up"].value_counts().plot(kind= "bar",
          title = "Votes Up or Down",
          figsize = (10,5))

start, end = seasons["Season 16"]
s16_mask = (df['created'] >= start) & (df['created'] <= end)
df_s16 = df.loc[s16_mask]
df_s16.tail()
df_s16["voted_up"].value_counts().plot(kind= "bar",
          title = "Votes Up or Down",
          figsize = (10,5))

start, end = seasons["Season 17"]
s17_mask = (df['created'] >= start) & (df['created'] <= end)
df_s17 = df.loc[s17_mask]
df_s17.tail()
df_s17["voted_up"].value_counts().plot(kind= "bar",
          title = "Votes Up or Down",
          figsize = (10,5))

start, end = seasons["Season 18"]
s18_mask = (df['created'] >= start) & (df['created'] <= end)
df_s18 = df.loc[s18_mask]
df_s18.tail()
df_s18["voted_up"].value_counts().plot(kind= "bar",
          title = "Votes Up or Down",
          figsize = (10,5))

start, end = seasons["Season 19"]
s19_mask = (df['created'] >= start) & (df['created'] <= end)
df_s19 = df.loc[s19_mask]
df_s19.head()
#Data Ends at Season 19
df_s19["voted_up"].value_counts().plot(kind= "bar",
          title = "Votes Up or Down",
          figsize = (10,5))

"""# VADER Model (Valence Aware Dictionary and Sentiment Reasoner)

"""

from nltk.sentiment import SentimentIntensityAnalyzer
nltk.download('vader_lexicon')

#Get function
sia = SentimentIntensityAnalyzer()
#Test
sia.polarity_scores("I hate this game")

sia.polarity_scores("I love this game")

s15_score = {}
for i, row in df_s15.iterrows():
  review = row["review"]
  id = row["id"]
  s15_score[id] = sia.polarity_scores(review)

vaders_s15 = pd.DataFrame(s15_score).T
vaders_s15 = vaders_s15.reset_index().rename(columns={"index":"id"})
vaders_s15 = vaders_s15.merge(df, on="id")
vaders_s15

s16_score = {}
for i, row in df_s16.iterrows():
  review = row["review"]
  id = row["id"]
  s16_score[id] = sia.polarity_scores(review)

vaders_s16 = pd.DataFrame(s16_score).T
vaders_s16 = vaders_s16.reset_index().rename(columns={"index":"id"})
vaders_s16 = vaders_s16.merge(df, on="id")

s17_score = {}
for i, row in df_s17.iterrows():
  review = row["review"]
  id = row["id"]
  s17_score[id] = sia.polarity_scores(review)

vaders_s17 = pd.DataFrame(s17_score).T
vaders_s17 = vaders_s17.reset_index().rename(columns={"index":"id"})
vaders_s17 = vaders_s17.merge(df, on="id")

s18_score = {}
for i, row in df_s18.iterrows():
  review = row["review"]
  id = row["id"]
  s18_score[id] = sia.polarity_scores(review)

vaders_s18 = pd.DataFrame(s18_score).T
vaders_s18 = vaders_s18.reset_index().rename(columns={"index":"id"})
vaders_s18 = vaders_s18.merge(df, on="id")

s19_score = {}
for i, row in df_s19.iterrows():
  review = row["review"]
  id = row["id"]
  s19_score[id] = sia.polarity_scores(review)

vaders_s19 = pd.DataFrame(s19_score).T
vaders_s19 = vaders_s19.reset_index().rename(columns={"index":"id"})
vaders_s19 = vaders_s19.merge(df, on="id")

s15_plot = sns.barplot(data = vaders_s15, x = "voted_up", y = "compound")
s15_plot.set_title("Compound Score by Vote")
plt.show()

s16_plot = sns.barplot(data = vaders_s16, x = "voted_up", y = "compound")
s16_plot.set_title("Compound Score by Vote")
plt.show()

s17_plot = sns.barplot(data = vaders_s17, x = "voted_up", y = "compound")
s17_plot.set_title("Compound Score by Vote")
plt.show()

s18_plot = sns.barplot(data = vaders_s18, x = "voted_up", y = "compound")
s18_plot.set_title("Compound Score by Vote")
plt.show()

s19_plot = sns.barplot(data = vaders_s19, x = "voted_up", y = "compound")
s19_plot.set_title("Compound Score by Vote")
plt.show()

fig,axs = plt.subplots(1,5, figsize = (15, 5))
sns.barplot(data = vaders_s15, x = "voted_up", y = "compound", ax =axs[0])
sns.barplot(data = vaders_s16, x = "voted_up", y = "compound", ax =axs[1])
sns.barplot(data = vaders_s17, x = "voted_up", y = "compound", ax =axs[2])
sns.barplot(data = vaders_s18, x = "voted_up", y = "compound", ax =axs[3])
sns.barplot(data = vaders_s19, x = "voted_up", y = "compound", ax =axs[4])
plt.show()

"""# Roberta Model"""

from transformers import AutoTokenizer
from transformers import AutoModelForSequenceClassification
from scipy.special import softmax

MODEL = f"cardiffnlp/twitter-roberta-base-sentiment"
tokenizer = AutoTokenizer.from_pretrained(MODEL)
model = AutoModelForSequenceClassification.from_pretrained(MODEL)

def polarity_scores_roberta(example_text):
  encoded_text = tokenizer(example_text, return_tensors = "pt")
  output = model(**encoded_text)
  scores = output[0][0].detach().numpy()
  scores = softmax(scores)
  scores_dict = {
      "roberta_neg": scores[0],
      "roberta_neu": scores[1],
      "roberta_pos": scores[2]
  }
  return scores_dict
polarity_scores_roberta("I hate this game")

s15_results = {}
for i, row in df_s15.iterrows():
  try:
    review = row["review"]
    id = row["id"]
    s15_vader_result = sia.polarity_scores(review)
    s15_vader_result_rename = {}
    for key, value in s15_vader_result.items():
      s15_vader_result_rename[f"vader_{key}"] = value
    s15_roberta_result = polarity_scores_roberta(review)
    both = {**s15_vader_result_rename, **s15_roberta_result}
    s15_results[id] = both
  except RuntimeError:
    print(f"Broke for id {id}")

from tqdm.notebook import tqdm

total_score_s15 = pd.DataFrame(s15_results).T
total_score_s15 = total_score_s15.reset_index().rename(columns={"index":"id"})
total_score_s15 = total_score_s15.merge(df_s15, on="id")
total_score_s15.tail()

s16_results = {}
for i, row in df_s16.iterrows():
    try:
        review = row["review"]
        id = row["id"]

        # Handle missing or invalid values
        if not isinstance(review, str) or not review.strip():
            review = ""

        # Vader
        s16_vader_result = sia.polarity_scores(review)
        s16_vader_result_rename = {f"vader_{k}": v for k, v in s16_vader_result.items()}

        if review:  # Only run RoBERTa if text is valid
            try:
                # Truncate long reviews to prevent index errors
                review_trunc = review[:512]
                s16_roberta_result = polarity_scores_roberta(review_trunc)
                both = {**s16_vader_result_rename, **s16_roberta_result}
                s16_results[id] = both
            except IndexError:
                print(f"Index error for id {id}, storing only VADER result")
                s16_results[id] = s16_vader_result_rename
        else:
            s16_results[id] = s16_vader_result_rename

    except RuntimeError:
        print(f"Broke for id {id}")

total_score_s16 = pd.DataFrame(s16_results).T
total_score_s16 = total_score_s16.reset_index().rename(columns={"index":"id"})
total_score_s16 = total_score_s16.merge(df_s16, on="id")
total_score_s16.tail()

s17_results = {}
for i, row in df_s17.iterrows():
  try:
    review = row["review"]
    id = row["id"]
    s17_vader_result = sia.polarity_scores(review)
    s17_vader_result_rename = {}
    for key, value in s17_vader_result.items():
      s17_vader_result_rename[f"vader_{key}"] = value
    if review: # Check if review is not empty
      s17_roberta_result = polarity_scores_roberta(review)
      both = {**s17_vader_result_rename, **s17_roberta_result}
      s17_results[id] = both
    else:
      s17_results[id] = s17_vader_result_rename
  except RuntimeError:
    print(f"Broke for id {id}")

total_score_s17 = pd.DataFrame(s17_results).T
total_score_s17 = total_score_s17.reset_index().rename(columns={"index":"id"})
total_score_s17 = total_score_s17.merge(df_s17, on="id")
total_score_s17.tail()

s18_results = {}
for i, row in df_s18.iterrows():
    try:
        review = row["review"]
        id = row["id"]

        # Handle missing or invalid values
        if not isinstance(review, str) or not review.strip():
            review = ""

        # Vader
        s18_vader_result = sia.polarity_scores(review)
        s18_vader_result_rename = {f"vader_{k}": v for k, v in s18_vader_result.items()}

        if review:  # Only run RoBERTa if text is valid
            try:
                # Truncate long reviews to prevent index errors
                review_trunc = review[:512]
                s18_roberta_result = polarity_scores_roberta(review_trunc)
                both = {**s18_vader_result_rename, **s18_roberta_result}
                s18_results[id] = both
            except IndexError:
                print(f"Index error for id {id}, storing only VADER result")
                s18_results[id] = s18_vader_result_rename
        else:
            s18_results[id] = s18_vader_result_rename

    except RuntimeError:
        print(f"Broke for id {id}")

total_score_s18 = pd.DataFrame(s18_results).T
total_score_s18 = total_score_s18.reset_index().rename(columns={"index":"id"})
total_score_s18 = total_score_s18.merge(df_s18, on="id")
total_score_s18.tail()

s19_results = {}
for i, row in df_s19.iterrows():
    try:
        review = row["review"]
        id = row["id"]

        # Handle missing or invalid values
        if not isinstance(review, str) or not review.strip():
            review = ""

        # Vader
        s19_vader_result = sia.polarity_scores(review)
        s19_vader_result_rename = {f"vader_{k}": v for k, v in s19_vader_result.items()}

        if review:  # Only run RoBERTa if text is valid
            try:
                # Truncate long reviews to prevent index errors
                review_trunc = review[:512]
                s19_roberta_result = polarity_scores_roberta(review_trunc)
                both = {**s19_vader_result_rename, **s19_roberta_result}
                s19_results[id] = both
            except IndexError:
                print(f"Index error for id {id}, storing only VADER result")
                s19_results[id] = s19_vader_result_rename
        else:
            s19_results[id] = s19_vader_result_rename

    except RuntimeError:
        print(f"Broke for id {id}")

total_score_s19 = pd.DataFrame(s19_results).T
total_score_s19 = total_score_s19.reset_index().rename(columns={"index":"id"})
total_score_s19 = total_score_s19.merge(df_s19, on="id")
total_score_s19.tail()

total_score_s15.to_csv("total_score_s15.csv")
total_score_s16.to_csv("total_score_s16.csv")
total_score_s17.to_csv("total_score_s17.csv")
total_score_s18.to_csv("total_score_s18.csv")
total_score_s19.to_csv("total_score_s19.csv")

"""# Comparing Model Results"""

sns.pairplot(data = total_score_s15, vars = ['vader_neg','vader_neu','vader_pos',
                                            'roberta_neg','roberta_neu','roberta_pos'],
             hue = "voted_up", palette = "tab10")
plt.show()

sns.pairplot(data = total_score_s16, vars = ['vader_neg','vader_neu','vader_pos',
                                            'roberta_neg','roberta_neu','roberta_pos'],
             hue = "voted_up", palette = "tab10")
plt.show()

sns.pairplot(data = total_score_s17, vars = ['vader_neg','vader_neu','vader_pos',
                                            'roberta_neg','roberta_neu','roberta_pos'],
             hue = "voted_up", palette = "tab10")
plt.show()

sns.pairplot(data = total_score_s18, vars = ['vader_neg','vader_neu','vader_pos',
                                            'roberta_neg','roberta_neu','roberta_pos'],
             hue = "voted_up", palette = "tab10")
plt.show()

sns.pairplot(data = total_score_s19, vars = ['vader_neg','vader_neu','vader_pos',
                                            'roberta_neg','roberta_neu','roberta_pos'],
             hue = "voted_up", palette = "tab10")
plt.show()

"""# Ranking Seasons

"""

mean_pos_values = [
    total_score_s15["roberta_pos"].mean(),
    total_score_s15["vader_pos"].mean(),
    total_score_s16["roberta_pos"].mean(),
    total_score_s16["vader_pos"].mean(),
    total_score_s17["roberta_pos"].mean(),
    total_score_s17["vader_pos"].mean(),
    total_score_s18["roberta_pos"].mean(),
    total_score_s18["vader_pos"].mean(),
    total_score_s19["roberta_pos"].mean(),
    total_score_s19["vader_pos"].mean()]
catagories = ["S15R", "S15V", "S16R", "S16V", "S17R", "S17V", "S18R", "S18V", "S19R", "S19V"]
plt.bar(catagories,mean_pos_values, color = 'lightgreen')

plt.xlabel('Seasons')
plt.ylabel('Mean Positive Sentiment')
plt.title('Mean Positive Sentiment by Season')

plt.show()

mean_neg_values = [
    total_score_s15["roberta_neg"].mean(),
    total_score_s15["vader_neg"].mean(),
    total_score_s16["roberta_neg"].mean(),
    total_score_s16["vader_neg"].mean(),
    total_score_s17["roberta_neg"].mean(),
    total_score_s17["vader_neg"].mean(),
    total_score_s18["roberta_neg"].mean(),
    total_score_s18["vader_neg"].mean(),
    total_score_s19["roberta_neg"].mean(),
    total_score_s19["vader_neg"].mean()]
catagories = ["S15R", "S15V", "S16R", "S16V", "S17R", "S17V", "S18R", "S18V", "S19R", "S19V"]
plt.bar(catagories,mean_neg_values, color = 'red')

plt.xlabel('Seasons')
plt.ylabel('Mean negative Sentiment')
plt.title('Mean negative Sentiment by Season')

plt.show()

mean_neu_values = [
    total_score_s15["roberta_neu"].mean(),
    total_score_s15["vader_neu"].mean(),
    total_score_s16["roberta_neu"].mean(),
    total_score_s16["vader_neu"].mean(),
    total_score_s17["roberta_neu"].mean(),
    total_score_s17["vader_neu"].mean(),
    total_score_s18["roberta_neu"].mean(),
    total_score_s18["vader_neu"].mean(),
    total_score_s19["roberta_neu"].mean(),
    total_score_s19["vader_neu"].mean()]
catagories = ["S15R", "S15V", "S16R", "S16V", "S17R", "S17V", "S18R", "S18V", "S19R", "S19V"]
plt.bar(catagories,mean_neu_values, color = 'grey')

plt.xlabel('Seasons')
plt.ylabel('Mean neutral Sentiment')
plt.title('Mean neutral Sentiment by Season')

plt.show()

"""# Further Analysis"""

sns.scatterplot(data = total_score_s15 , y = "roberta_pos", x = "author_playtime_at_review")
plt.show()

sns.scatterplot(data = total_score_s16 , y = "roberta_pos", x = "author_playtime_at_review")
plt.show()

sns.scatterplot(data = total_score_s17 , y = "roberta_pos", x = "author_playtime_at_review")
plt.show()

sns.scatterplot(data = total_score_s18 , y = "roberta_pos", x = "author_playtime_at_review")
plt.show()

sns.scatterplot(data = total_score_s19 , y = "roberta_pos", x = "author_playtime_at_review")
plt.show()